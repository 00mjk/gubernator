// Code generated by protoc-gen-go. DO NOT EDIT.
// source: ratelimit.proto

package pb

import proto "github.com/golang/protobuf/proto"
import fmt "fmt"
import math "math"
import _ "google.golang.org/genproto/googleapis/api/annotations"

import (
	context "golang.org/x/net/context"
	grpc "google.golang.org/grpc"
)

// Reference imports to suppress errors if they are not otherwise used.
var _ = proto.Marshal
var _ = fmt.Errorf
var _ = math.Inf

type Algorithm int32

const (
	// Token bucket algorithm https://en.wikipedia.org/wiki/Token_bucket
	Algorithm_TOKEN_BUCKET Algorithm = 0
	// Leaky bucket algorithm https://en.wikipedia.org/wiki/Leaky_bucket
	Algorithm_LEAKY_BUCKET Algorithm = 1
)

var Algorithm_name = map[int32]string{
	0: "TOKEN_BUCKET",
	1: "LEAKY_BUCKET",
}
var Algorithm_value = map[string]int32{
	"TOKEN_BUCKET": 0,
	"LEAKY_BUCKET": 1,
}

func (x Algorithm) String() string {
	return proto.EnumName(Algorithm_name, int32(x))
}
func (Algorithm) EnumDescriptor() ([]byte, []int) { return fileDescriptor1, []int{0} }

type Behavior int32

const (
	// BATCHING is the default behavior. This enables batching requests which protects the
	// service from thundering herd. IE: When a service experiences spikes of unexpected high
	// volume requests.
	//
	// Using this option introduces a small amount of latency depending on
	// the `batchWait` setting. Defaults to around 500 Microseconds of additional
	// latency in low throughput situations. For high volume loads, batching can reduce
	// the overall load on the system substantially.
	Behavior_BATCHING Behavior = 0
	// Disables batching. Use this for super low latency rate limit requests when
	// thundering herd is not a concern but latency of requests is of paramount importance.
	Behavior_NO_BATCHING Behavior = 1
	// Enables Global caching of the rate limit. Use this if the rate limit applies globally to
	// all ingress requests. (IE: Throttle hundreds of thousands of requests to an entire
	// datacenter or cluster of http servers)
	//
	// Using this option gubernator will continue to use a single peer as the rate limit coordinator
	// to increment and manage the state of the rate limit, however the result of the rate limit is
	// distributed to each peer and cached locally. A rate limit request received from any peer in the
	// cluster will first check the local cache for a rate limit answer, if it exists the peer will
	// immediately return the answer to the client and asynchronously forward the aggregate hits to
	// the peer coordinator. Because of GLOBALS async nature we lose some accuracy in rate limit
	// reporting, which may result in allowing some requests beyond the chosen rate limit. However we
	// gain massive performance as every request coming into the system does not have to wait for a
	// single peer to decide if the rate limit has been reached.
	Behavior_GLOBAL Behavior = 2
)

var Behavior_name = map[int32]string{
	0: "BATCHING",
	1: "NO_BATCHING",
	2: "GLOBAL",
}
var Behavior_value = map[string]int32{
	"BATCHING":    0,
	"NO_BATCHING": 1,
	"GLOBAL":      2,
}

func (x Behavior) String() string {
	return proto.EnumName(Behavior_name, int32(x))
}
func (Behavior) EnumDescriptor() ([]byte, []int) { return fileDescriptor1, []int{1} }

type Status int32

const (
	Status_UNDER_LIMIT Status = 0
	Status_OVER_LIMIT  Status = 1
)

var Status_name = map[int32]string{
	0: "UNDER_LIMIT",
	1: "OVER_LIMIT",
}
var Status_value = map[string]int32{
	"UNDER_LIMIT": 0,
	"OVER_LIMIT":  1,
}

func (x Status) String() string {
	return proto.EnumName(Status_name, int32(x))
}
func (Status) EnumDescriptor() ([]byte, []int) { return fileDescriptor1, []int{2} }

// Must specify at least one RateLimitRequest.
type RateLimitRequestList struct {
	RateLimits []*RateLimitRequest `protobuf:"bytes,1,rep,name=rate_limits,json=rateLimits" json:"rate_limits,omitempty"`
}

func (m *RateLimitRequestList) Reset()                    { *m = RateLimitRequestList{} }
func (m *RateLimitRequestList) String() string            { return proto.CompactTextString(m) }
func (*RateLimitRequestList) ProtoMessage()               {}
func (*RateLimitRequestList) Descriptor() ([]byte, []int) { return fileDescriptor1, []int{0} }

func (m *RateLimitRequestList) GetRateLimits() []*RateLimitRequest {
	if m != nil {
		return m.RateLimits
	}
	return nil
}

// Responses are in the same order as they appeared in the RateLimitsRequest
type RateLimitResponseList struct {
	RateLimits []*RateLimitResponse `protobuf:"bytes,1,rep,name=rate_limits,json=rateLimits" json:"rate_limits,omitempty"`
}

func (m *RateLimitResponseList) Reset()                    { *m = RateLimitResponseList{} }
func (m *RateLimitResponseList) String() string            { return proto.CompactTextString(m) }
func (*RateLimitResponseList) ProtoMessage()               {}
func (*RateLimitResponseList) Descriptor() ([]byte, []int) { return fileDescriptor1, []int{1} }

func (m *RateLimitResponseList) GetRateLimits() []*RateLimitResponse {
	if m != nil {
		return m.RateLimits
	}
	return nil
}

type RateLimitRequest struct {
	// The namespace scopes the unique_key to avoid collisions with other services or applications.
	Namespace string `protobuf:"bytes,1,opt,name=namespace" json:"namespace,omitempty"`
	// Uniquely identifies this rate limit within a namespace.
	UniqueKey string `protobuf:"bytes,2,opt,name=unique_key,json=uniqueKey" json:"unique_key,omitempty"`
	// Rate limit requests optionally specify the number of hits a request adds to the matched limit. If Hit
	// is zero, the request returns the current limit, but does not increment the hit count.
	Hits int64 `protobuf:"varint,3,opt,name=hits" json:"hits,omitempty"`
	// The number of requests that can occur for the duration of the rate limit
	Limit int64 `protobuf:"varint,4,opt,name=limit" json:"limit,omitempty"`
	// The duration of the rate limit in milliseconds
	// Second = 1000 Milliseconds
	// Minute = 60000 Milliseconds
	// Hour = 3600000 Milliseconds
	Duration int64 `protobuf:"varint,5,opt,name=duration" json:"duration,omitempty"`
	// The algorithm used to calculate the rate limit. The algorithm may change on
	// subsequent requests, when this occurs any previous rate limit hit counts are reset.
	Algorithm Algorithm `protobuf:"varint,6,opt,name=algorithm,enum=pb.gubernator.Algorithm" json:"algorithm,omitempty"`
	// The behavior of the rate limit in gubernator.
	Behavior Behavior `protobuf:"varint,7,opt,name=behavior,enum=pb.gubernator.Behavior" json:"behavior,omitempty"`
}

func (m *RateLimitRequest) Reset()                    { *m = RateLimitRequest{} }
func (m *RateLimitRequest) String() string            { return proto.CompactTextString(m) }
func (*RateLimitRequest) ProtoMessage()               {}
func (*RateLimitRequest) Descriptor() ([]byte, []int) { return fileDescriptor1, []int{2} }

func (m *RateLimitRequest) GetNamespace() string {
	if m != nil {
		return m.Namespace
	}
	return ""
}

func (m *RateLimitRequest) GetUniqueKey() string {
	if m != nil {
		return m.UniqueKey
	}
	return ""
}

func (m *RateLimitRequest) GetHits() int64 {
	if m != nil {
		return m.Hits
	}
	return 0
}

func (m *RateLimitRequest) GetLimit() int64 {
	if m != nil {
		return m.Limit
	}
	return 0
}

func (m *RateLimitRequest) GetDuration() int64 {
	if m != nil {
		return m.Duration
	}
	return 0
}

func (m *RateLimitRequest) GetAlgorithm() Algorithm {
	if m != nil {
		return m.Algorithm
	}
	return Algorithm_TOKEN_BUCKET
}

func (m *RateLimitRequest) GetBehavior() Behavior {
	if m != nil {
		return m.Behavior
	}
	return Behavior_BATCHING
}

type RateLimitResponse struct {
	// The status of the rate limit.
	Status Status `protobuf:"varint,1,opt,name=status,enum=pb.gubernator.Status" json:"status,omitempty"`
	// The currently configured request limit (Identical to RateLimitRequest.rate_limit_config.limit).
	CurrentLimit int64 `protobuf:"varint,2,opt,name=current_limit,json=currentLimit" json:"current_limit,omitempty"`
	// This is the number of requests remaining before the limit is hit.
	LimitRemaining int64 `protobuf:"varint,3,opt,name=limit_remaining,json=limitRemaining" json:"limit_remaining,omitempty"`
	// This is the time when the rate limit span will be reset, provided as a unix timestamp in milliseconds.
	ResetTime int64 `protobuf:"varint,4,opt,name=reset_time,json=resetTime" json:"reset_time,omitempty"`
	// Contains the error; If set all other values should be ignored
	Error string `protobuf:"bytes,5,opt,name=error" json:"error,omitempty"`
	// This is additional metadata that a client might find useful. (IE: Additional headers, corrdinator ownership, etc..)
	Metadata map[string]string `protobuf:"bytes,6,rep,name=metadata" json:"metadata,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"`
}

func (m *RateLimitResponse) Reset()                    { *m = RateLimitResponse{} }
func (m *RateLimitResponse) String() string            { return proto.CompactTextString(m) }
func (*RateLimitResponse) ProtoMessage()               {}
func (*RateLimitResponse) Descriptor() ([]byte, []int) { return fileDescriptor1, []int{3} }

func (m *RateLimitResponse) GetStatus() Status {
	if m != nil {
		return m.Status
	}
	return Status_UNDER_LIMIT
}

func (m *RateLimitResponse) GetCurrentLimit() int64 {
	if m != nil {
		return m.CurrentLimit
	}
	return 0
}

func (m *RateLimitResponse) GetLimitRemaining() int64 {
	if m != nil {
		return m.LimitRemaining
	}
	return 0
}

func (m *RateLimitResponse) GetResetTime() int64 {
	if m != nil {
		return m.ResetTime
	}
	return 0
}

func (m *RateLimitResponse) GetError() string {
	if m != nil {
		return m.Error
	}
	return ""
}

func (m *RateLimitResponse) GetMetadata() map[string]string {
	if m != nil {
		return m.Metadata
	}
	return nil
}

type HealthCheckRequest struct {
}

func (m *HealthCheckRequest) Reset()                    { *m = HealthCheckRequest{} }
func (m *HealthCheckRequest) String() string            { return proto.CompactTextString(m) }
func (*HealthCheckRequest) ProtoMessage()               {}
func (*HealthCheckRequest) Descriptor() ([]byte, []int) { return fileDescriptor1, []int{4} }

type HealthCheckResponse struct {
	// Valid entries are 'healthy' or 'unhealthy'
	Status string `protobuf:"bytes,1,opt,name=status" json:"status,omitempty"`
	// If 'unhealthy', message indicates the problem
	Message string `protobuf:"bytes,2,opt,name=message" json:"message,omitempty"`
	// The number of peers we know about
	PeerCount int32 `protobuf:"varint,3,opt,name=peer_count,json=peerCount" json:"peer_count,omitempty"`
}

func (m *HealthCheckResponse) Reset()                    { *m = HealthCheckResponse{} }
func (m *HealthCheckResponse) String() string            { return proto.CompactTextString(m) }
func (*HealthCheckResponse) ProtoMessage()               {}
func (*HealthCheckResponse) Descriptor() ([]byte, []int) { return fileDescriptor1, []int{5} }

func (m *HealthCheckResponse) GetStatus() string {
	if m != nil {
		return m.Status
	}
	return ""
}

func (m *HealthCheckResponse) GetMessage() string {
	if m != nil {
		return m.Message
	}
	return ""
}

func (m *HealthCheckResponse) GetPeerCount() int32 {
	if m != nil {
		return m.PeerCount
	}
	return 0
}

func init() {
	proto.RegisterType((*RateLimitRequestList)(nil), "pb.gubernator.RateLimitRequestList")
	proto.RegisterType((*RateLimitResponseList)(nil), "pb.gubernator.RateLimitResponseList")
	proto.RegisterType((*RateLimitRequest)(nil), "pb.gubernator.RateLimitRequest")
	proto.RegisterType((*RateLimitResponse)(nil), "pb.gubernator.RateLimitResponse")
	proto.RegisterType((*HealthCheckRequest)(nil), "pb.gubernator.HealthCheckRequest")
	proto.RegisterType((*HealthCheckResponse)(nil), "pb.gubernator.HealthCheckResponse")
	proto.RegisterEnum("pb.gubernator.Algorithm", Algorithm_name, Algorithm_value)
	proto.RegisterEnum("pb.gubernator.Behavior", Behavior_name, Behavior_value)
	proto.RegisterEnum("pb.gubernator.Status", Status_name, Status_value)
}

// Reference imports to suppress errors if they are not otherwise used.
var _ context.Context
var _ grpc.ClientConn

// This is a compile-time assertion to ensure that this generated file
// is compatible with the grpc package it is being compiled against.
const _ = grpc.SupportPackageIsVersion4

// Client API for RateLimitService service

type RateLimitServiceClient interface {
	// Given a list of rate limits return the rates and statuses of each request.
	GetRateLimits(ctx context.Context, in *RateLimitRequestList, opts ...grpc.CallOption) (*RateLimitResponseList, error)
	// This method is for round trip benchmarking and can be used by
	// the client to determine connectivity to the server
	HealthCheck(ctx context.Context, in *HealthCheckRequest, opts ...grpc.CallOption) (*HealthCheckResponse, error)
}

type rateLimitServiceClient struct {
	cc *grpc.ClientConn
}

func NewRateLimitServiceClient(cc *grpc.ClientConn) RateLimitServiceClient {
	return &rateLimitServiceClient{cc}
}

func (c *rateLimitServiceClient) GetRateLimits(ctx context.Context, in *RateLimitRequestList, opts ...grpc.CallOption) (*RateLimitResponseList, error) {
	out := new(RateLimitResponseList)
	err := grpc.Invoke(ctx, "/pb.gubernator.RateLimitService/GetRateLimits", in, out, c.cc, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *rateLimitServiceClient) HealthCheck(ctx context.Context, in *HealthCheckRequest, opts ...grpc.CallOption) (*HealthCheckResponse, error) {
	out := new(HealthCheckResponse)
	err := grpc.Invoke(ctx, "/pb.gubernator.RateLimitService/HealthCheck", in, out, c.cc, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

// Server API for RateLimitService service

type RateLimitServiceServer interface {
	// Given a list of rate limits return the rates and statuses of each request.
	GetRateLimits(context.Context, *RateLimitRequestList) (*RateLimitResponseList, error)
	// This method is for round trip benchmarking and can be used by
	// the client to determine connectivity to the server
	HealthCheck(context.Context, *HealthCheckRequest) (*HealthCheckResponse, error)
}

func RegisterRateLimitServiceServer(s *grpc.Server, srv RateLimitServiceServer) {
	s.RegisterService(&_RateLimitService_serviceDesc, srv)
}

func _RateLimitService_GetRateLimits_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(RateLimitRequestList)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(RateLimitServiceServer).GetRateLimits(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/pb.gubernator.RateLimitService/GetRateLimits",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(RateLimitServiceServer).GetRateLimits(ctx, req.(*RateLimitRequestList))
	}
	return interceptor(ctx, in, info, handler)
}

func _RateLimitService_HealthCheck_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(HealthCheckRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(RateLimitServiceServer).HealthCheck(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/pb.gubernator.RateLimitService/HealthCheck",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(RateLimitServiceServer).HealthCheck(ctx, req.(*HealthCheckRequest))
	}
	return interceptor(ctx, in, info, handler)
}

var _RateLimitService_serviceDesc = grpc.ServiceDesc{
	ServiceName: "pb.gubernator.RateLimitService",
	HandlerType: (*RateLimitServiceServer)(nil),
	Methods: []grpc.MethodDesc{
		{
			MethodName: "GetRateLimits",
			Handler:    _RateLimitService_GetRateLimits_Handler,
		},
		{
			MethodName: "HealthCheck",
			Handler:    _RateLimitService_HealthCheck_Handler,
		},
	},
	Streams:  []grpc.StreamDesc{},
	Metadata: "ratelimit.proto",
}

func init() { proto.RegisterFile("ratelimit.proto", fileDescriptor1) }

var fileDescriptor1 = []byte{
	// 695 bytes of a gzipped FileDescriptorProto
	0x1f, 0x8b, 0x08, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, 0xff, 0x84, 0x54, 0xdd, 0x6e, 0xda, 0x4c,
	0x10, 0x8d, 0x21, 0x21, 0x78, 0x08, 0x3f, 0xd9, 0x2f, 0x3f, 0x16, 0xca, 0xa7, 0x52, 0xa7, 0x52,
	0x29, 0x52, 0x41, 0x25, 0x6a, 0x55, 0xa5, 0x37, 0x05, 0x8a, 0x92, 0x14, 0x02, 0x92, 0x43, 0xaa,
	0x36, 0x37, 0xd6, 0x42, 0xa6, 0x60, 0x05, 0xdb, 0x64, 0xbd, 0x46, 0xcd, 0x5d, 0x95, 0x57, 0xe8,
	0x7b, 0xf5, 0xa6, 0xaf, 0xd0, 0xb7, 0xe8, 0x4d, 0xb5, 0x6b, 0xe3, 0x00, 0x69, 0x9b, 0x3b, 0xcf,
	0x99, 0x99, 0x33, 0xeb, 0x33, 0x67, 0x17, 0xb2, 0x8c, 0x72, 0x1c, 0x5b, 0xb6, 0xc5, 0xcb, 0x13,
	0xe6, 0x72, 0x97, 0xa4, 0x27, 0xfd, 0xf2, 0xd0, 0xef, 0x23, 0x73, 0x28, 0x77, 0x59, 0x7e, 0x6f,
	0xe8, 0xba, 0xc3, 0x31, 0x56, 0xe8, 0xc4, 0xaa, 0x50, 0xc7, 0x71, 0x39, 0xe5, 0x96, 0xeb, 0x78,
	0x41, 0xb1, 0xfe, 0x11, 0xb6, 0x0c, 0xca, 0xb1, 0x2d, 0xfa, 0x0d, 0xbc, 0xf6, 0xd1, 0xe3, 0x6d,
	0xcb, 0xe3, 0xe4, 0x2d, 0xa4, 0x04, 0xaf, 0x29, 0x89, 0x3d, 0x4d, 0x29, 0xc4, 0x8b, 0xa9, 0xea,
	0xa3, 0xf2, 0x02, 0x75, 0x79, 0xb9, 0xd3, 0x00, 0x36, 0x43, 0x3c, 0xfd, 0x02, 0xb6, 0xe7, 0xf2,
	0xde, 0xc4, 0x75, 0x3c, 0x94, 0xd4, 0xb5, 0x3f, 0x51, 0x17, 0xfe, 0x4e, 0x1d, 0xb4, 0x2e, 0x70,
	0xdf, 0xc6, 0x20, 0xb7, 0x3c, 0x9c, 0xec, 0x81, 0xea, 0x50, 0x1b, 0xbd, 0x09, 0x1d, 0xa0, 0xa6,
	0x14, 0x94, 0xa2, 0x6a, 0xdc, 0x01, 0xe4, 0x7f, 0x00, 0xdf, 0xb1, 0xae, 0x7d, 0x34, 0xaf, 0xf0,
	0x46, 0x8b, 0x05, 0xe9, 0x00, 0x69, 0xe1, 0x0d, 0x21, 0xb0, 0x3a, 0x12, 0xa7, 0x89, 0x17, 0x94,
	0x62, 0xdc, 0x90, 0xdf, 0x64, 0x0b, 0xd6, 0xe4, 0x19, 0xb5, 0x55, 0x09, 0x06, 0x01, 0xc9, 0x43,
	0xf2, 0xd2, 0x67, 0x52, 0x44, 0x6d, 0x4d, 0x26, 0xa2, 0x98, 0xbc, 0x02, 0x95, 0x8e, 0x87, 0x2e,
	0xb3, 0xf8, 0xc8, 0xd6, 0x12, 0x05, 0xa5, 0x98, 0xa9, 0x6a, 0x4b, 0x3f, 0x56, 0x9b, 0xe5, 0x8d,
	0xbb, 0x52, 0x72, 0x00, 0xc9, 0x3e, 0x8e, 0xe8, 0xd4, 0x72, 0x99, 0xb6, 0x2e, 0xdb, 0x76, 0x97,
	0xda, 0xea, 0x61, 0xda, 0x88, 0x0a, 0xf5, 0xef, 0x31, 0xd8, 0xbc, 0x27, 0x13, 0x79, 0x0e, 0x09,
	0x8f, 0x53, 0xee, 0x7b, 0x52, 0x82, 0x4c, 0x75, 0x7b, 0x89, 0xe8, 0x4c, 0x26, 0x8d, 0xb0, 0x88,
	0xec, 0x43, 0x7a, 0xe0, 0x33, 0x86, 0x0e, 0x0f, 0xf6, 0x21, 0x95, 0x89, 0x1b, 0x1b, 0x21, 0x28,
	0xb9, 0xc9, 0x53, 0xc8, 0xca, 0xa4, 0xc9, 0xd0, 0xa6, 0x96, 0x63, 0x39, 0xc3, 0x50, 0xa7, 0xcc,
	0x38, 0x98, 0x1d, 0xa2, 0x42, 0x64, 0x86, 0x1e, 0x72, 0x93, 0x5b, 0x36, 0x86, 0xb2, 0xa9, 0x12,
	0xe9, 0x59, 0x36, 0x0a, 0x41, 0x91, 0x31, 0x97, 0x49, 0xdd, 0x54, 0x23, 0x08, 0xc8, 0x7b, 0x48,
	0xda, 0xc8, 0xe9, 0x25, 0xe5, 0x54, 0x4b, 0x48, 0x33, 0x94, 0x1f, 0x32, 0x43, 0xf9, 0x34, 0x6c,
	0x68, 0x3a, 0x9c, 0xdd, 0x18, 0x51, 0x7f, 0xfe, 0x0d, 0xa4, 0x17, 0x52, 0x24, 0x07, 0x71, 0xb1,
	0xef, 0xc0, 0x0e, 0xe2, 0x53, 0x1c, 0x62, 0x4a, 0xc7, 0x3e, 0x86, 0x1e, 0x08, 0x82, 0xc3, 0xd8,
	0x6b, 0x45, 0xdf, 0x02, 0x72, 0x8c, 0x74, 0xcc, 0x47, 0x8d, 0x11, 0x0e, 0xae, 0x42, 0x5b, 0xe9,
	0x9f, 0xe1, 0xbf, 0x05, 0x34, 0xd4, 0x79, 0x67, 0x41, 0x67, 0x35, 0x12, 0x54, 0x83, 0x75, 0x1b,
	0x3d, 0x8f, 0x0e, 0x67, 0x03, 0x66, 0xa1, 0x10, 0x67, 0x82, 0xc8, 0xcc, 0x81, 0xeb, 0x3b, 0x5c,
	0x0a, 0xb8, 0x66, 0xa8, 0x02, 0x69, 0x08, 0xa0, 0x54, 0x01, 0x35, 0xf2, 0x06, 0xc9, 0xc1, 0x46,
	0xaf, 0xdb, 0x6a, 0x76, 0xcc, 0xfa, 0x79, 0xa3, 0xd5, 0xec, 0xe5, 0x56, 0x04, 0xd2, 0x6e, 0xd6,
	0x5a, 0x9f, 0x66, 0x88, 0x52, 0x7a, 0x09, 0xc9, 0x99, 0x2b, 0xc8, 0x06, 0x24, 0xeb, 0xb5, 0x5e,
	0xe3, 0xf8, 0xa4, 0x73, 0x94, 0x5b, 0x21, 0x59, 0x48, 0x75, 0xba, 0x66, 0x04, 0x28, 0x04, 0x20,
	0x71, 0xd4, 0xee, 0xd6, 0x6b, 0xed, 0x5c, 0xac, 0xf4, 0x0c, 0x12, 0x81, 0x07, 0x44, 0xd9, 0x79,
	0xe7, 0x5d, 0xd3, 0x30, 0xdb, 0x27, 0xa7, 0x27, 0x62, 0x46, 0x06, 0xa0, 0xfb, 0x21, 0x8a, 0x95,
	0xea, 0x2f, 0x65, 0xee, 0x9a, 0x9d, 0x21, 0x9b, 0x5a, 0x03, 0x24, 0x5f, 0x20, 0x7d, 0x84, 0x3c,
	0x82, 0x3d, 0xb2, 0xff, 0xc0, 0xab, 0x20, 0x2e, 0x7d, 0xfe, 0xc9, 0x43, 0x2b, 0x15, 0x55, 0xfa,
	0xde, 0xed, 0x8f, 0x9f, 0xdf, 0x62, 0x3b, 0xfa, 0x66, 0x65, 0xfa, 0xa2, 0xb2, 0x30, 0xe5, 0x50,
	0x29, 0x11, 0x1b, 0x52, 0x73, 0x9b, 0x20, 0x8f, 0x97, 0x28, 0xef, 0xef, 0x2e, 0xaf, 0xff, 0xab,
	0x24, 0x98, 0xab, 0xef, 0xca, 0x99, 0x9b, 0x24, 0x2b, 0x66, 0xce, 0x15, 0xd4, 0xd7, 0x2f, 0x62,
	0x93, 0xfe, 0x57, 0x45, 0xe9, 0x27, 0xe4, 0x53, 0x79, 0xf0, 0x3b, 0x00, 0x00, 0xff, 0xff, 0xd0,
	0x48, 0x52, 0xf3, 0x6a, 0x05, 0x00, 0x00,
}
