// Code generated by protoc-gen-go. DO NOT EDIT.
// source: ratelimit.proto

package pb

import proto "github.com/golang/protobuf/proto"
import fmt "fmt"
import math "math"
import _ "google.golang.org/genproto/googleapis/api/annotations"

import (
	context "golang.org/x/net/context"
	grpc "google.golang.org/grpc"
)

// Reference imports to suppress errors if they are not otherwise used.
var _ = proto.Marshal
var _ = fmt.Errorf
var _ = math.Inf

type RateLimitConfig_Algorithm int32

const (
	RateLimitConfig_TOKEN_BUCKET RateLimitConfig_Algorithm = 0
	RateLimitConfig_LEAKY_BUCKET RateLimitConfig_Algorithm = 1
)

var RateLimitConfig_Algorithm_name = map[int32]string{
	0: "TOKEN_BUCKET",
	1: "LEAKY_BUCKET",
}
var RateLimitConfig_Algorithm_value = map[string]int32{
	"TOKEN_BUCKET": 0,
	"LEAKY_BUCKET": 1,
}

func (x RateLimitConfig_Algorithm) String() string {
	return proto.EnumName(RateLimitConfig_Algorithm_name, int32(x))
}
func (RateLimitConfig_Algorithm) EnumDescriptor() ([]byte, []int) { return fileDescriptor1, []int{3, 0} }

type RateLimitConfig_Behavior int32

const (
	// BATCHING is the default behavior. This enables batching requests which protects the
	// service from thundering herd. IE: When a service experiences spikes of unexpected high
	// volume requests.
	//
	// Using this option introduces a small amount of latency depending on
	// the `batchWait` setting. Defaults to around 500 Microseconds of additional
	// latency in low throughput situations. For high volume loads, batching can reduce
	// the overall load on the system substantially.
	RateLimitConfig_BATCHING RateLimitConfig_Behavior = 0
	// Disables batching. Use this for super low latency rate limit requests when
	// thundering herd is not a concern but latency of requests is of paramount importance.
	RateLimitConfig_NO_BATCHING RateLimitConfig_Behavior = 1
	// Enables Global caching of the rate limit. Use this if the rate limit applies globally to
	// all ingress requests. (IE: Throttle hundreds of thousands of requests to an entire
	// datacenter or cluster of http servers)
	//
	// Using this option gubernator will continue to use a single peer as the rate limit coordinator
	// to increment and manage the state of the rate limit, however the result of the rate limit is
	// distributed to each peer and cached locally. A rate limit request received from any peer in the
	// cluster will first check the local cache for a rate limit answer, if it exists the peer will
	// immediately return the answer to the client and asynchronously forward the aggregate hits to
	// the peer coordinator. Because of GLOBALS async nature we lose some accuracy in rate limit
	// reporting, which may result in allowing some requests beyond the chosen rate limit. However we
	// gain massive performance as every request coming into the system does not have to wait for a
	// single peer to decide if the rate limit has been reached.
	RateLimitConfig_GLOBAL RateLimitConfig_Behavior = 2
)

var RateLimitConfig_Behavior_name = map[int32]string{
	0: "BATCHING",
	1: "NO_BATCHING",
	2: "GLOBAL",
}
var RateLimitConfig_Behavior_value = map[string]int32{
	"BATCHING":    0,
	"NO_BATCHING": 1,
	"GLOBAL":      2,
}

func (x RateLimitConfig_Behavior) String() string {
	return proto.EnumName(RateLimitConfig_Behavior_name, int32(x))
}
func (RateLimitConfig_Behavior) EnumDescriptor() ([]byte, []int) { return fileDescriptor1, []int{3, 1} }

type RateLimitResponse_Status int32

const (
	RateLimitResponse_UNDER_LIMIT RateLimitResponse_Status = 0
	RateLimitResponse_OVER_LIMIT  RateLimitResponse_Status = 1
)

var RateLimitResponse_Status_name = map[int32]string{
	0: "UNDER_LIMIT",
	1: "OVER_LIMIT",
}
var RateLimitResponse_Status_value = map[string]int32{
	"UNDER_LIMIT": 0,
	"OVER_LIMIT":  1,
}

func (x RateLimitResponse_Status) String() string {
	return proto.EnumName(RateLimitResponse_Status_name, int32(x))
}
func (RateLimitResponse_Status) EnumDescriptor() ([]byte, []int) { return fileDescriptor1, []int{4, 0} }

// Must specify at least one RateLimitRequest.
type RateLimitRequestList struct {
	RateLimits []*RateLimitRequest `protobuf:"bytes,1,rep,name=rate_limits,json=rateLimits" json:"rate_limits,omitempty"`
}

func (m *RateLimitRequestList) Reset()                    { *m = RateLimitRequestList{} }
func (m *RateLimitRequestList) String() string            { return proto.CompactTextString(m) }
func (*RateLimitRequestList) ProtoMessage()               {}
func (*RateLimitRequestList) Descriptor() ([]byte, []int) { return fileDescriptor1, []int{0} }

func (m *RateLimitRequestList) GetRateLimits() []*RateLimitRequest {
	if m != nil {
		return m.RateLimits
	}
	return nil
}

// Responses are in the same order as they appeared in the RateLimitsRequest
type RateLimitResponseList struct {
	RateLimits []*RateLimitResponse `protobuf:"bytes,1,rep,name=rate_limits,json=rateLimits" json:"rate_limits,omitempty"`
}

func (m *RateLimitResponseList) Reset()                    { *m = RateLimitResponseList{} }
func (m *RateLimitResponseList) String() string            { return proto.CompactTextString(m) }
func (*RateLimitResponseList) ProtoMessage()               {}
func (*RateLimitResponseList) Descriptor() ([]byte, []int) { return fileDescriptor1, []int{1} }

func (m *RateLimitResponseList) GetRateLimits() []*RateLimitResponse {
	if m != nil {
		return m.RateLimits
	}
	return nil
}

type RateLimitRequest struct {
	// The namespace scopes the unique_key to avoid collisions with other services or applications.
	Namespace string `protobuf:"bytes,1,opt,name=namespace" json:"namespace,omitempty"`
	// Uniquely identifies this rate limit within a namespace.
	UniqueKey string `protobuf:"bytes,2,opt,name=unique_key,json=uniqueKey" json:"unique_key,omitempty"`
	// Rate limit requests optionally specify the number of hits a request adds to the matched limit. If the
	// value is not set, a request increases the matched limit by 1.
	Hits int64 `protobuf:"varint,3,opt,name=hits" json:"hits,omitempty"`
	// This is the rate limit configuration provided by the client. The configuration may change on
	// subsequent requests, however when this occurs any previous rate limit counts are reset.
	RateLimitConfig *RateLimitConfig `protobuf:"bytes,4,opt,name=rate_limit_config,json=rateLimitConfig" json:"rate_limit_config,omitempty"`
}

func (m *RateLimitRequest) Reset()                    { *m = RateLimitRequest{} }
func (m *RateLimitRequest) String() string            { return proto.CompactTextString(m) }
func (*RateLimitRequest) ProtoMessage()               {}
func (*RateLimitRequest) Descriptor() ([]byte, []int) { return fileDescriptor1, []int{2} }

func (m *RateLimitRequest) GetNamespace() string {
	if m != nil {
		return m.Namespace
	}
	return ""
}

func (m *RateLimitRequest) GetUniqueKey() string {
	if m != nil {
		return m.UniqueKey
	}
	return ""
}

func (m *RateLimitRequest) GetHits() int64 {
	if m != nil {
		return m.Hits
	}
	return 0
}

func (m *RateLimitRequest) GetRateLimitConfig() *RateLimitConfig {
	if m != nil {
		return m.RateLimitConfig
	}
	return nil
}

// Defines a rate limit duration and requests per duration
type RateLimitConfig struct {
	// The number of requests that can occur for the duration of the rate limit
	Limit int64 `protobuf:"varint,1,opt,name=limit" json:"limit,omitempty"`
	// The duration of the rate limit in milliseconds
	// Second = 1000 Milliseconds
	// Minute = 60000 Milliseconds
	// Hour = 3600000 Milliseconds
	Duration int64 `protobuf:"varint,2,opt,name=duration" json:"duration,omitempty"`
	// The algorithm used to calculate the rate limit
	Algorithm RateLimitConfig_Algorithm `protobuf:"varint,3,opt,name=algorithm,enum=pb.gubernator.RateLimitConfig_Algorithm" json:"algorithm,omitempty"`
	// The behavior of the rate limit in gubernator.
	Behavior RateLimitConfig_Behavior `protobuf:"varint,4,opt,name=behavior,enum=pb.gubernator.RateLimitConfig_Behavior" json:"behavior,omitempty"`
}

func (m *RateLimitConfig) Reset()                    { *m = RateLimitConfig{} }
func (m *RateLimitConfig) String() string            { return proto.CompactTextString(m) }
func (*RateLimitConfig) ProtoMessage()               {}
func (*RateLimitConfig) Descriptor() ([]byte, []int) { return fileDescriptor1, []int{3} }

func (m *RateLimitConfig) GetLimit() int64 {
	if m != nil {
		return m.Limit
	}
	return 0
}

func (m *RateLimitConfig) GetDuration() int64 {
	if m != nil {
		return m.Duration
	}
	return 0
}

func (m *RateLimitConfig) GetAlgorithm() RateLimitConfig_Algorithm {
	if m != nil {
		return m.Algorithm
	}
	return RateLimitConfig_TOKEN_BUCKET
}

func (m *RateLimitConfig) GetBehavior() RateLimitConfig_Behavior {
	if m != nil {
		return m.Behavior
	}
	return RateLimitConfig_BATCHING
}

type RateLimitResponse struct {
	// The status of the rate limit.
	Status RateLimitResponse_Status `protobuf:"varint,1,opt,name=status,enum=pb.gubernator.RateLimitResponse_Status" json:"status,omitempty"`
	// The currently configured request limit (Identical to RateLimitRequest.rate_limit_config.limit).
	CurrentLimit int64 `protobuf:"varint,2,opt,name=current_limit,json=currentLimit" json:"current_limit,omitempty"`
	// This is the number of requests remaining before the limit is hit.
	LimitRemaining int64 `protobuf:"varint,3,opt,name=limit_remaining,json=limitRemaining" json:"limit_remaining,omitempty"`
	// This is the time when the rate limit span will be reset, provided as a unix timestamp in milliseconds.
	ResetTime int64 `protobuf:"varint,4,opt,name=reset_time,json=resetTime" json:"reset_time,omitempty"`
	// Contains the error; If set all other values should be ignored
	Error string `protobuf:"bytes,5,opt,name=error" json:"error,omitempty"`
	// This is additional metadata that a client might find useful. (IE: Additional headers, corrdinator ownership, etc..)
	Metadata map[string]string `protobuf:"bytes,6,rep,name=metadata" json:"metadata,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"`
}

func (m *RateLimitResponse) Reset()                    { *m = RateLimitResponse{} }
func (m *RateLimitResponse) String() string            { return proto.CompactTextString(m) }
func (*RateLimitResponse) ProtoMessage()               {}
func (*RateLimitResponse) Descriptor() ([]byte, []int) { return fileDescriptor1, []int{4} }

func (m *RateLimitResponse) GetStatus() RateLimitResponse_Status {
	if m != nil {
		return m.Status
	}
	return RateLimitResponse_UNDER_LIMIT
}

func (m *RateLimitResponse) GetCurrentLimit() int64 {
	if m != nil {
		return m.CurrentLimit
	}
	return 0
}

func (m *RateLimitResponse) GetLimitRemaining() int64 {
	if m != nil {
		return m.LimitRemaining
	}
	return 0
}

func (m *RateLimitResponse) GetResetTime() int64 {
	if m != nil {
		return m.ResetTime
	}
	return 0
}

func (m *RateLimitResponse) GetError() string {
	if m != nil {
		return m.Error
	}
	return ""
}

func (m *RateLimitResponse) GetMetadata() map[string]string {
	if m != nil {
		return m.Metadata
	}
	return nil
}

type HealthCheckRequest struct {
}

func (m *HealthCheckRequest) Reset()                    { *m = HealthCheckRequest{} }
func (m *HealthCheckRequest) String() string            { return proto.CompactTextString(m) }
func (*HealthCheckRequest) ProtoMessage()               {}
func (*HealthCheckRequest) Descriptor() ([]byte, []int) { return fileDescriptor1, []int{5} }

type HealthCheckResponse struct {
	// Valid entries are 'healthy' or 'unhealthy'
	Status string `protobuf:"bytes,1,opt,name=status" json:"status,omitempty"`
	// If 'unhealthy' message indicates the problem
	Message string `protobuf:"bytes,2,opt,name=message" json:"message,omitempty"`
	// The number of peers we know about
	PeerCount int32 `protobuf:"varint,3,opt,name=peer_count,json=peerCount" json:"peer_count,omitempty"`
}

func (m *HealthCheckResponse) Reset()                    { *m = HealthCheckResponse{} }
func (m *HealthCheckResponse) String() string            { return proto.CompactTextString(m) }
func (*HealthCheckResponse) ProtoMessage()               {}
func (*HealthCheckResponse) Descriptor() ([]byte, []int) { return fileDescriptor1, []int{6} }

func (m *HealthCheckResponse) GetStatus() string {
	if m != nil {
		return m.Status
	}
	return ""
}

func (m *HealthCheckResponse) GetMessage() string {
	if m != nil {
		return m.Message
	}
	return ""
}

func (m *HealthCheckResponse) GetPeerCount() int32 {
	if m != nil {
		return m.PeerCount
	}
	return 0
}

func init() {
	proto.RegisterType((*RateLimitRequestList)(nil), "pb.gubernator.RateLimitRequestList")
	proto.RegisterType((*RateLimitResponseList)(nil), "pb.gubernator.RateLimitResponseList")
	proto.RegisterType((*RateLimitRequest)(nil), "pb.gubernator.RateLimitRequest")
	proto.RegisterType((*RateLimitConfig)(nil), "pb.gubernator.RateLimitConfig")
	proto.RegisterType((*RateLimitResponse)(nil), "pb.gubernator.RateLimitResponse")
	proto.RegisterType((*HealthCheckRequest)(nil), "pb.gubernator.HealthCheckRequest")
	proto.RegisterType((*HealthCheckResponse)(nil), "pb.gubernator.HealthCheckResponse")
	proto.RegisterEnum("pb.gubernator.RateLimitConfig_Algorithm", RateLimitConfig_Algorithm_name, RateLimitConfig_Algorithm_value)
	proto.RegisterEnum("pb.gubernator.RateLimitConfig_Behavior", RateLimitConfig_Behavior_name, RateLimitConfig_Behavior_value)
	proto.RegisterEnum("pb.gubernator.RateLimitResponse_Status", RateLimitResponse_Status_name, RateLimitResponse_Status_value)
}

// Reference imports to suppress errors if they are not otherwise used.
var _ context.Context
var _ grpc.ClientConn

// This is a compile-time assertion to ensure that this generated file
// is compatible with the grpc package it is being compiled against.
const _ = grpc.SupportPackageIsVersion4

// Client API for RateLimitService service

type RateLimitServiceClient interface {
	// Given a list of rate limits return the rates and statuses of each request.
	GetRateLimits(ctx context.Context, in *RateLimitRequestList, opts ...grpc.CallOption) (*RateLimitResponseList, error)
	// This method is for round trip benchmarking and can be used by
	// the client to determine connectivity to the server
	HealthCheck(ctx context.Context, in *HealthCheckRequest, opts ...grpc.CallOption) (*HealthCheckResponse, error)
}

type rateLimitServiceClient struct {
	cc *grpc.ClientConn
}

func NewRateLimitServiceClient(cc *grpc.ClientConn) RateLimitServiceClient {
	return &rateLimitServiceClient{cc}
}

func (c *rateLimitServiceClient) GetRateLimits(ctx context.Context, in *RateLimitRequestList, opts ...grpc.CallOption) (*RateLimitResponseList, error) {
	out := new(RateLimitResponseList)
	err := grpc.Invoke(ctx, "/pb.gubernator.RateLimitService/GetRateLimits", in, out, c.cc, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *rateLimitServiceClient) HealthCheck(ctx context.Context, in *HealthCheckRequest, opts ...grpc.CallOption) (*HealthCheckResponse, error) {
	out := new(HealthCheckResponse)
	err := grpc.Invoke(ctx, "/pb.gubernator.RateLimitService/HealthCheck", in, out, c.cc, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

// Server API for RateLimitService service

type RateLimitServiceServer interface {
	// Given a list of rate limits return the rates and statuses of each request.
	GetRateLimits(context.Context, *RateLimitRequestList) (*RateLimitResponseList, error)
	// This method is for round trip benchmarking and can be used by
	// the client to determine connectivity to the server
	HealthCheck(context.Context, *HealthCheckRequest) (*HealthCheckResponse, error)
}

func RegisterRateLimitServiceServer(s *grpc.Server, srv RateLimitServiceServer) {
	s.RegisterService(&_RateLimitService_serviceDesc, srv)
}

func _RateLimitService_GetRateLimits_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(RateLimitRequestList)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(RateLimitServiceServer).GetRateLimits(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/pb.gubernator.RateLimitService/GetRateLimits",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(RateLimitServiceServer).GetRateLimits(ctx, req.(*RateLimitRequestList))
	}
	return interceptor(ctx, in, info, handler)
}

func _RateLimitService_HealthCheck_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(HealthCheckRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(RateLimitServiceServer).HealthCheck(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/pb.gubernator.RateLimitService/HealthCheck",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(RateLimitServiceServer).HealthCheck(ctx, req.(*HealthCheckRequest))
	}
	return interceptor(ctx, in, info, handler)
}

var _RateLimitService_serviceDesc = grpc.ServiceDesc{
	ServiceName: "pb.gubernator.RateLimitService",
	HandlerType: (*RateLimitServiceServer)(nil),
	Methods: []grpc.MethodDesc{
		{
			MethodName: "GetRateLimits",
			Handler:    _RateLimitService_GetRateLimits_Handler,
		},
		{
			MethodName: "HealthCheck",
			Handler:    _RateLimitService_HealthCheck_Handler,
		},
	},
	Streams:  []grpc.StreamDesc{},
	Metadata: "ratelimit.proto",
}

func init() { proto.RegisterFile("ratelimit.proto", fileDescriptor1) }

var fileDescriptor1 = []byte{
	// 732 bytes of a gzipped FileDescriptorProto
	0x1f, 0x8b, 0x08, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, 0xff, 0x84, 0x54, 0x4d, 0x6f, 0xda, 0x4c,
	0x10, 0x8e, 0x71, 0x42, 0x60, 0x08, 0x5f, 0xfb, 0xe6, 0xcd, 0x8b, 0x50, 0xde, 0x96, 0x3a, 0x95,
	0x42, 0x7b, 0x00, 0x95, 0xaa, 0x52, 0x95, 0x1e, 0x5a, 0xa0, 0x34, 0x1f, 0x10, 0x90, 0x1c, 0x52,
	0xb5, 0xb9, 0x58, 0x0b, 0x99, 0x80, 0x15, 0x6c, 0x93, 0xf5, 0x1a, 0x35, 0xb7, 0xaa, 0xd7, 0x1e,
	0xfb, 0x43, 0x7a, 0xed, 0xff, 0xe8, 0x5f, 0xe8, 0xbf, 0xe8, 0xa5, 0xda, 0xb5, 0x71, 0x80, 0x34,
	0xe1, 0xe6, 0x79, 0x3c, 0xcf, 0x33, 0xb3, 0xcf, 0xcc, 0x2e, 0xa4, 0x19, 0xe5, 0x38, 0x32, 0x2d,
	0x93, 0x97, 0xc6, 0xcc, 0xe1, 0x0e, 0x49, 0x8e, 0x7b, 0xa5, 0x81, 0xd7, 0x43, 0x66, 0x53, 0xee,
	0xb0, 0xfc, 0xf6, 0xc0, 0x71, 0x06, 0x23, 0x2c, 0xd3, 0xb1, 0x59, 0xa6, 0xb6, 0xed, 0x70, 0xca,
	0x4d, 0xc7, 0x76, 0xfd, 0x64, 0xed, 0x03, 0x6c, 0xea, 0x94, 0x63, 0x4b, 0xf0, 0x75, 0xbc, 0xf2,
	0xd0, 0xe5, 0x2d, 0xd3, 0xe5, 0xe4, 0x0d, 0x24, 0x84, 0xae, 0x21, 0x85, 0xdd, 0x9c, 0x52, 0x50,
	0x8b, 0x89, 0xca, 0xc3, 0xd2, 0x9c, 0x74, 0x69, 0x91, 0xa9, 0x03, 0x9b, 0x22, 0xae, 0x76, 0x06,
	0xff, 0xce, 0xfc, 0x77, 0xc7, 0x8e, 0xed, 0xa2, 0x94, 0xae, 0xfe, 0x4d, 0xba, 0x70, 0xb7, 0xb4,
	0x4f, 0x9d, 0xd3, 0xfe, 0xae, 0x40, 0x66, 0xb1, 0x38, 0xd9, 0x86, 0xb8, 0x4d, 0x2d, 0x74, 0xc7,
	0xb4, 0x8f, 0x39, 0xa5, 0xa0, 0x14, 0xe3, 0xfa, 0x0d, 0x40, 0xfe, 0x07, 0xf0, 0x6c, 0xf3, 0xca,
	0x43, 0xe3, 0x12, 0xaf, 0x73, 0x11, 0xff, 0xb7, 0x8f, 0x34, 0xf1, 0x9a, 0x10, 0x58, 0x1d, 0x8a,
	0x6e, 0xd4, 0x82, 0x52, 0x54, 0x75, 0xf9, 0x4d, 0x8e, 0x20, 0x7b, 0xd3, 0xa8, 0xd1, 0x77, 0xec,
	0x0b, 0x73, 0x90, 0x5b, 0x2d, 0x28, 0xc5, 0x44, 0xe5, 0xc1, 0x5d, 0xed, 0xd6, 0x65, 0x96, 0x9e,
	0x66, 0xf3, 0x80, 0xf6, 0x23, 0x02, 0xe9, 0x85, 0x24, 0xb2, 0x09, 0x6b, 0x52, 0x5a, 0x36, 0xab,
	0xea, 0x7e, 0x40, 0xf2, 0x10, 0x3b, 0xf7, 0x98, 0x1c, 0x92, 0x6c, 0x53, 0xd5, 0xc3, 0x98, 0xbc,
	0x83, 0x38, 0x1d, 0x0d, 0x1c, 0x66, 0xf2, 0xa1, 0x25, 0x5b, 0x4d, 0x55, 0x8a, 0xf7, 0x77, 0x52,
	0xaa, 0x4e, 0xf3, 0xf5, 0x1b, 0x2a, 0xa9, 0x43, 0xac, 0x87, 0x43, 0x3a, 0x31, 0x1d, 0x26, 0x0f,
	0x94, 0xaa, 0xec, 0x2e, 0x91, 0xa9, 0x05, 0xe9, 0x7a, 0x48, 0xd4, 0xca, 0x10, 0x0f, 0xc5, 0x49,
	0x06, 0x36, 0xba, 0x9d, 0x66, 0xa3, 0x6d, 0xd4, 0x4e, 0xeb, 0xcd, 0x46, 0x37, 0xb3, 0x22, 0x90,
	0x56, 0xa3, 0xda, 0xfc, 0x38, 0x45, 0x14, 0xed, 0x05, 0xc4, 0xa6, 0x32, 0x64, 0x03, 0x62, 0xb5,
	0x6a, 0xb7, 0x7e, 0x70, 0xd8, 0xde, 0xcf, 0xac, 0x90, 0x34, 0x24, 0xda, 0x1d, 0x23, 0x04, 0x14,
	0x02, 0x10, 0xdd, 0x6f, 0x75, 0x6a, 0xd5, 0x56, 0x26, 0xa2, 0x7d, 0x55, 0x21, 0x7b, 0x6b, 0x1d,
	0xc8, 0x6b, 0x88, 0xba, 0x9c, 0x72, 0xcf, 0x95, 0xee, 0xdd, 0x73, 0x80, 0x29, 0xa3, 0x74, 0x22,
	0xd3, 0xf5, 0x80, 0x46, 0x76, 0x20, 0xd9, 0xf7, 0x18, 0x43, 0x9b, 0xfb, 0x03, 0x0e, 0xcc, 0xde,
	0x08, 0x40, 0xc9, 0x25, 0xbb, 0x90, 0xf6, 0xa7, 0xcf, 0xd0, 0xa2, 0xa6, 0x6d, 0xda, 0x83, 0x60,
	0x43, 0x52, 0x23, 0x5f, 0x3b, 0x40, 0xc5, 0x7a, 0x31, 0x74, 0x91, 0x1b, 0xdc, 0xb4, 0x50, 0x7a,
	0xaa, 0xea, 0x71, 0x89, 0x74, 0x4d, 0x0b, 0xc5, 0xa8, 0x91, 0x31, 0x87, 0xe5, 0xd6, 0xe4, 0xe2,
	0xf9, 0x01, 0x39, 0x82, 0x98, 0x85, 0x9c, 0x9e, 0x53, 0x4e, 0x73, 0x51, 0x79, 0x0d, 0x4a, 0x4b,
	0x4f, 0x71, 0x1c, 0x10, 0x1a, 0x36, 0x67, 0xd7, 0x7a, 0xc8, 0xcf, 0xbf, 0x82, 0xe4, 0xdc, 0x2f,
	0x92, 0x01, 0x55, 0x6c, 0xba, 0x7f, 0x11, 0xc4, 0xa7, 0x68, 0x62, 0x42, 0x47, 0x1e, 0x06, 0xdb,
	0xef, 0x07, 0x7b, 0x91, 0x97, 0x8a, 0xf6, 0x04, 0xa2, 0xbe, 0x3b, 0x62, 0x12, 0xa7, 0xed, 0xb7,
	0x0d, 0xdd, 0x68, 0x1d, 0x1e, 0x1f, 0x8a, 0x31, 0xa6, 0x00, 0x3a, 0xef, 0xc3, 0x58, 0xd1, 0x36,
	0x81, 0x1c, 0x20, 0x1d, 0xf1, 0x61, 0x7d, 0x88, 0xfd, 0xcb, 0xe0, 0xee, 0x69, 0x17, 0xf0, 0xcf,
	0x1c, 0x1a, 0x0c, 0x69, 0x6b, 0x6e, 0x48, 0xf1, 0xd0, 0xfb, 0x1c, 0xac, 0x5b, 0xe8, 0xba, 0x74,
	0x30, 0xed, 0x65, 0x1a, 0x0a, 0x1f, 0xc7, 0x88, 0xcc, 0xe8, 0x3b, 0x9e, 0xcd, 0xa5, 0xd7, 0x6b,
	0x7a, 0x5c, 0x20, 0x75, 0x01, 0x54, 0x7e, 0xcf, 0x5e, 0xfc, 0x13, 0x64, 0x13, 0xb3, 0x8f, 0xe4,
	0x13, 0x24, 0xf7, 0x91, 0x87, 0xb0, 0x4b, 0x76, 0x96, 0xbc, 0x53, 0xe2, 0x19, 0xca, 0x3f, 0x5e,
	0x66, 0xb5, 0xc8, 0xd2, 0xb6, 0xbf, 0xfc, 0xfc, 0xf5, 0x2d, 0xb2, 0xa5, 0x65, 0xcb, 0x93, 0x67,
	0xe5, 0xb9, 0x2a, 0x7b, 0xca, 0x53, 0x62, 0x41, 0x62, 0xe6, 0xd8, 0xe4, 0xd1, 0x82, 0xe4, 0x6d,
	0xa3, 0xf2, 0xda, 0x7d, 0x29, 0x7e, 0x5d, 0xed, 0x3f, 0x59, 0x33, 0x4b, 0xd2, 0xa2, 0xe6, 0x4c,
	0x42, 0x6d, 0xfd, 0x2c, 0x32, 0xee, 0x7d, 0x56, 0x94, 0x5e, 0x54, 0x3e, 0xde, 0xcf, 0xff, 0x04,
	0x00, 0x00, 0xff, 0xff, 0xa9, 0x35, 0x90, 0x5e, 0xfc, 0x05, 0x00, 0x00,
}
